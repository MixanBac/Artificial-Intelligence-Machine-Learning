{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Библиотека работы с массивами\n",
    "import os\n",
    "from abc import abstractmethod # Позволяет указывать на абстрактные методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder): # Загрузка numpy массивов\n",
    "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder, 'y_train.npy'))    \n",
    "    x_test = np.load(os.path.join(folder, 'x_test.npy'))    \n",
    "    y_test = np.load(os.path.join(folder, 'y_test.npy'))    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_preds_correct(your_preds, sklearn_preds) -> bool: # Оценка корректности предсказанных классов\n",
    "    return np.abs(your_preds - sklearn_preds).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_probs_correct(your_probs, sklearn_probs) -> bool: # Сравнение схожести вероятности принадлежности к классам к аналогичным из sklearn\n",
    "    return np.abs(your_probs - sklearn_probs).mean() < 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, n_classes): # Храним n классов\n",
    "        self.n_classes = n_classes\n",
    "        self.params = dict() # Параметры в словаре\n",
    "        \n",
    "    # --- PREDICTION ---\n",
    "        \n",
    "    def predict(self, x, return_probs=False): # Функция предсказания\n",
    "        \"\"\"\n",
    "        x - np.array размерности [N, dim], \n",
    "        где N - количество экземпляров данных, \n",
    "        dim -размерность одного экземпляра (количество признаков).\n",
    "        \n",
    "        Возвращает np.array размерности [N], содержащий номера классов для\n",
    "        соответствующих экземпляров.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for sample in x:\n",
    "            preds.append(\n",
    "                self.predict_single(sample, return_probs=return_probs) # Каждый экзепляр проходит через предикцию и получаем ответ\n",
    "            )\n",
    "        \n",
    "        if return_probs:\n",
    "            return np.array(preds, dtype='float32')\n",
    "        \n",
    "        return np.array(preds, dtype='int32')\n",
    "    \n",
    "    def predict_single(self, x, return_probs=False) -> int: \n",
    "        \"\"\"\n",
    "        Делает предсказание для одного экземпляра данных.\n",
    "        \n",
    "        x - np.array размерности dim.\n",
    "        \n",
    "        Возвращает номер класса, которому принадлежит x.\n",
    "        \"\"\"\n",
    "        assert len(x.shape) == 1, f'Expected a vector, but received a tensor of shape={x.shape}'\n",
    "        marginal_prob = self.compute_marginal_probability(x)  # P(x) - безусловная вероятность появления x\n",
    "        \n",
    "        probs = []\n",
    "        for c in range(self.n_classes):                 # c - номер класса\n",
    "            prior = self.compute_prior(c)               # P(c) - априорная вероятность (вероятность появления класса)\n",
    "            likelihood = self.compute_likelihood(x, c)  # P(x|c) - вероятность появления x в предположении, что он принаждлежит c\n",
    "            \n",
    "            # Используем теорему Байесса для просчёта условной вероятности P(c|x)\n",
    "            # P(c|x) = P(c) * P(x|c) / P(x)\n",
    "            prob = prior * likelihood / marginal_prob\n",
    "            probs.append(prob)\n",
    "            \n",
    "        if return_probs:\n",
    "            return probs\n",
    "        \n",
    "        return np.argmax(probs)\n",
    "    \n",
    "    # Вычисляет P(x) - безусловная вероятность появления x.\n",
    "    @abstractmethod\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        pass\n",
    "    \n",
    "    # Вычисляет P(c) - безусловная вероятность появления класса c (априорная вероятность).\n",
    "    @abstractmethod\n",
    "    def compute_prior(self, c) -> float:\n",
    "        pass\n",
    "    \n",
    "    # Вычисляет P(x|c) - условная вероятность появления x в предположении, что он принаждлежит c.\n",
    "    @abstractmethod\n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        pass\n",
    "    \n",
    "    # --- FITTING ---\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self._estimate_prior(y)\n",
    "        self._estimate_params(x, y)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _estimate_prior(self, y):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _estimate_params(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Наивный классификатор Байеса: гауссово распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите недостающий код, создайте и обучите модель. \n",
    "\n",
    "Пункты оценки:\n",
    "1. совпадение предсказанных классов с оными у модели sklearn. Для проверки совпадения используйте функцию `assert_preds_correct`.\n",
    "2. совпадение значений предсказанных вероятностей принадлежности классами с оными у модели sklearn. Значения вероятностей считаются равными, если функция `assert_probs_correct` возвращает True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('gauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp # Данная функция "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveGauss(NaiveBayes):\n",
    "    def __init__(self, n_classes, logs_variant=False):\n",
    "        \"\"\"\n",
    "        Получим Наивный Байес, который имеет распределение Гаусса\n",
    "        Тогда можно найти параметры, такие как математическое ожидание, дисперсия и так далее\n",
    "        \"\"\"\n",
    "        super().__init__(n_classes)\n",
    "        self.logs_variant = logs_variant\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        n_features = x. shape[1]\n",
    "        # Инициализация переменных\n",
    "        self.params['class_count'] = np.zeros(self.n_classes, dtype=np.float32) # Частота\n",
    "        self.params['prior'] = np.zeros(self.n_classes, dtype=np.float32)\n",
    "        self.params['theta'] = np.zeros((self.n_classes, n_features), dtype=np.float32) # Математическое ожидание\n",
    "        self.params['var'] = np.zeros((self.n_classes, n_features), dtype=np.float32) # Дисперсия\n",
    "        self.params['std'] = np.zeros((self.n_classes, n_features), dtype=np.float32) # Корень из дисперсии\n",
    "        \n",
    "        # Значения априорных вероятностей сохраните в 'params' с ключом 'prior'\n",
    "        # Напишите свой код здесь\n",
    "        for y_i in np.unique(y): # Для каждого класса считаем статистики, которые в дальнейшем используем\n",
    "            # y - количество вхождений определенного класса\n",
    "            # Получаем индексы всех уникальных классов, которые используем в выборке\n",
    "            # Берем выборку с известным классом\n",
    "            x_i = x[y == y_i] \n",
    "            self.params['theta'][y_i] = np.mean(x_i, axis=0)\n",
    "            self.params['var'][y_i] = np.var(x_i, axis=0)\n",
    "            self.params['std'][y_i] = np.std(x_i, axis=0)\n",
    "            self.params['class_count'][y_i] = np.sum(y == y_i)\n",
    "        self.params['prior'][:] = self.params['class_count'] / np.sum(self.params['class_count'])\n",
    "    \n",
    "    \n",
    "    # Вычисляет P(x) - безусловная вероятность появления x\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        # Для просчёта безусловной вероятности используйте \n",
    "        # методы compute_prior и compute_likelihood.\n",
    "        # Напишите свой код здесь\n",
    "        # Z = sum(p(c_i) * p(x| c_i))\n",
    "        return np.sum(\n",
    "            [               # p(c_i) * p(x | c_i)\n",
    "                self.compute_prior(y_i) * self.compute_likelihood(x, y_i)\n",
    "                for y_i in range(self.n_classes)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    # Вычисляет P(c) - безусловная вероятность появления класса c (априорная вероятность)\n",
    "    def compute_prior(self, c) -> float:\n",
    "        assert abs(sum(self.params['prior']) - 1.0) < 1e-3, \\\n",
    "            f\"Sum of prior probabilities must be equal to 1, but is {sum(self.params['prior'])}\"\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        # Напишите свой код здесь\n",
    "        return self.params['prior'][c]\n",
    "    \n",
    "    # Вычисляет P(x|c) - условная вероятность появления x в предположении, что он принаждлежит c.\n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        # Напишите свой код здесь\n",
    "        var = self.params['var'][c][None, :] # Используем ранее рассчитанные значения\n",
    "        std = self.params['std'][c][None, :]\n",
    "        theta = self.params['theta'][c][None, :]\n",
    "        \n",
    "        # В этом примере N = 1 для x, именно поэтому мы можем использовать функцию squeeze\n",
    "        if self.logs_variant:\n",
    "            return np.squeeze(self.likelihood_logs(x, var, std, theta)) # Функция squeeze() удаляет оси с одним элементом (длинной 1), но не сами элементы массива\n",
    "        return np.squeeze(self.likelihood_scratch(x, var, std, theta))\n",
    "    \n",
    "    def likelihood_scratch(self, x, var, std, theta): # Проверяет входит ли экземпляр данных в распределение (формула плотности вероятности)\n",
    "        # x - вектор признаков\n",
    "        # Посчитаем плотность вероятности в \"лоб\" по сухим формулам\n",
    "        res = 1 / (np.sqrt(2* np.pi) * std)\n",
    "        res *= np.exp((-0.5) * (((x - theta) ** 2) / var))\n",
    "        # (N, n_features) ->(N,)\n",
    "        return np.prod(res, axis = 1)\n",
    "    \n",
    "    def likelihood_logs(self, x, var, std, theta): # Проверяет входит ли экземпляр данных в распределение (формула плотности вероятности),\n",
    "                                                   # с помощью логарифмирования функции плотности вероятности Гауссовского распределения \n",
    "        # Посчитаем плотность вероятности\n",
    "        res = -0.5 * np.sum(np.log(2.0 * np.pi * var))\n",
    "        res *= 0.5 * np.sum(((x - theta) ** 2) / var)\n",
    "        joint_log_likelihood = np.array(res).T # (N, n_features) ->(n_features, N)\n",
    "        res = logsumexp(res, axis = 0) # (n_features, N) -> (N,)\n",
    "        return np.exp(res)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель\n",
    "model = NaiveGauss(len(np.unique(y_train)), logs_variant=False)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оцените качество модели\n",
    "preds = model.predict(x_test)\n",
    "np.mean(preds == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баесовский классификатор написан верно, так как точность равна единице. Ошибок нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds corrent? True\n",
      "probs corrent? True\n"
     ]
    }
   ],
   "source": [
    "# Сравните вашу модель с аналогом sklearn (GaussianNB)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "\n",
    "print(f'preds corrent? {assert_preds_correct(model.predict(x_test), gnb.predict(x_test))}')\n",
    "print(f'probs corrent? {assert_probs_correct(model.predict(x_test, True), gnb.predict_proba(x_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По данному сравнению можно сделать вывод, что модель работает аналогично аналогу из sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сравним работу модели, реализованной с помощью логарифмированния функции плотности вероятности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель\n",
    "model = NaiveGauss(len(np.unique(y_train)), logs_variant=True)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оцените качество модели\n",
    "preds = model.predict(x_test)\n",
    "np.mean(preds == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баесовский классификатор написан верно, так как точность равна единице. Ошибок нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds corrent? True\n",
      "probs corrent? True\n"
     ]
    }
   ],
   "source": [
    "# Сравните вашу модель с аналогом sklearn (GaussianNB)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "\n",
    "print(f'preds corrent? {assert_preds_correct(model.predict(x_test), gnb.predict(x_test))}')\n",
    "print(f'probs corrent? {assert_probs_correct(model.predict(x_test, True), gnb.predict_proba(x_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По данному сравнению можно сделать вывод, что модель работает аналогично аналогу из sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Доп. задания (любое на выбор, опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1  Упрощение наивного классификатора Байеса для гауссова распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберите из класса NaiveBayes 'лишние' вычисления и удалите код, что соответствует этим вычислениям. Под 'лишним' подразумеваются вещи, что не влияют на итоговое решение о принадлежности классу (значения вероятностей при этом могу стать некорректными, но в данном задании это допустимо).\n",
    "\n",
    "Напишите в клетке ниже код упрощенного 'классификатора Гаусса' и убедитесь, что его ответы (не значения вероятностей) совпадают с ответами классификатора из задания 1.\n",
    "\n",
    "Указание: работайте в предположении, что классы равновероятны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишите обновленный код модели здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцените качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравните вашу модель с моделью из задания 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1  Наивный классификатор Байеса: мультиномиальное распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите недостающий код, создайте и обучите модель.\n",
    "\n",
    "Подсказка: в определении функции правдоподобия много факториалов. Для избежания численного переполнения посчитайте сначала логарифм функции правдоподобия, после примените экспоненту для получения значения вероятности.\n",
    "\n",
    "Пункты оценки аналогичны оным из задания 1.\n",
    "\n",
    "Сложность: математический гений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "При желании данный класс можно переписать с нуля. Изменения должны сопровождаться комментариями.\n",
    "\"\"\"\n",
    "class NaiveMultinomial(NaiveBayes):\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        # Для просчёта безусловной вероятности используйте \n",
    "        # методы compute_prior и compute_likelihood.\n",
    "        # Напишите свой код здесь\n",
    "        pass\n",
    "    \n",
    "    def compute_prior(self, c) -> float:\n",
    "        assert abs(sum(self.params['prior']) - 1.0) < 1e-3, \\\n",
    "            f\"Sum of prior probabilities must be equal to 1, but is {sum(self.params['prior'])}\"\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        # Напишите свой код здесь\n",
    "        pass\n",
    "    \n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        # Напишите свой код здесь\n",
    "        pass\n",
    "    \n",
    "    # --- FITTING ---\n",
    "    \n",
    "    def _estimate_prior(self, y):\n",
    "        # Значения априорных вероятностей сохраните в `params` с ключом 'prior'\n",
    "        # Напишите свой код здесь\n",
    "        pass\n",
    "    \n",
    "    def _estimate_params(self, x, y):\n",
    "        # Напишите свой код здесь\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцените качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравните вашу модель с аналогом sklearn (MultinomialNB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
